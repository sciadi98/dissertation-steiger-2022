{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b2162fb-87b6-41e1-9317-9d687b9c160c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-17T10:19:31.836707Z",
     "end_time": "2023-04-17T10:19:40.942456Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\r\n",
      "  Using cached numpy-1.24.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\r\n",
      "Collecting matplotlib\r\n",
      "  Using cached matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\r\n",
      "Collecting pandas\r\n",
      "  Downloading pandas-2.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.3/12.3 MB\u001B[0m \u001B[31m63.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\r\n",
      "\u001B[?25hCollecting openpyxl\r\n",
      "  Downloading openpyxl-3.1.2-py2.py3-none-any.whl (249 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m250.0/250.0 kB\u001B[0m \u001B[31m93.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting sklearn\r\n",
      "  Downloading sklearn-0.0.post4.tar.gz (3.6 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hCollecting seaborn\r\n",
      "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m293.3/293.3 kB\u001B[0m \u001B[31m112.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hRequirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.10/site-packages (from matplotlib) (2.8.2)\r\n",
      "Collecting fonttools>=4.22.0\r\n",
      "  Downloading fonttools-4.39.3-py3-none-any.whl (1.0 MB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.0/1.0 MB\u001B[0m \u001B[31m97.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting pillow>=6.2.0\r\n",
      "  Using cached Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)\r\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from matplotlib) (23.1)\r\n",
      "Collecting cycler>=0.10\r\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\r\n",
      "Collecting pyparsing>=2.3.1\r\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\r\n",
      "Collecting contourpy>=1.0.1\r\n",
      "  Using cached contourpy-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\r\n",
      "Collecting kiwisolver>=1.0.1\r\n",
      "  Using cached kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\r\n",
      "Collecting tzdata>=2022.1\r\n",
      "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m341.8/341.8 kB\u001B[0m \u001B[31m104.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting pytz>=2020.1\r\n",
      "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m502.3/502.3 kB\u001B[0m \u001B[31m107.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hCollecting et-xmlfile\r\n",
      "  Using cached et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\r\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\r\n",
      "Installing collected packages: sklearn, pytz, tzdata, pyparsing, pillow, numpy, kiwisolver, fonttools, et-xmlfile, cycler, pandas, openpyxl, contourpy, matplotlib, seaborn\r\n",
      "\u001B[33m  DEPRECATION: sklearn is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\u001B[0m\u001B[33m\r\n",
      "\u001B[0m  Running setup.py install for sklearn ... \u001B[?25ldone\r\n",
      "\u001B[?25hSuccessfully installed contourpy-1.0.7 cycler-0.11.0 et-xmlfile-1.1.0 fonttools-4.39.3 kiwisolver-1.4.4 matplotlib-3.7.1 numpy-1.24.2 openpyxl-3.1.2 pandas-2.0.0 pillow-9.5.0 pyparsing-3.0.9 pytz-2023.3 seaborn-0.12.2 sklearn-0.0.post4 tzdata-2023.3\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m23.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy matplotlib pandas openpyxl sklearn seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08a44b0a-736b-4f01-9b98-f0519aa27c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and global options\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import multiprocessing\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af73e3eb-3c1c-413a-8e83-03253b46b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "def prepare_dataset(dataset_file, input_cols, result_col=None):\n",
    "    # Load data\n",
    "    df = pd.read_excel(dataset_file)\n",
    "    \n",
    "    # Filter bad data, replace categories with dummies\n",
    "    x_df = df[input_cols].apply(lambda x: x.str.strip())\n",
    "    x = pd.get_dummies(x_df, drop_first=True)\n",
    "    \n",
    "    if result_col:\n",
    "        y_df = df[result_col].str.strip()\n",
    "        y = pd.get_dummies(y_df, drop_first=True).iloc[:, 0]\n",
    "        \n",
    "        return x, y\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a791342c-2708-4e9a-b307-65cc5609a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and dummies displayed in a table\n",
    "def display_input_data(dataset_file, input_cols):\n",
    "    x = prepare_dataset(dataset_file, input_cols)\n",
    "    display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20ff6a4f-2ab8-4d7f-bddb-082a93769038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_input_data_indices(train_dataset_file, test_dataset_file, input_cols):\n",
    "    x_train = prepare_dataset(train_dataset_file, input_cols)\n",
    "    x_test = prepare_dataset(test_dataset_file, input_cols)\n",
    "    \n",
    "    if not x_train.columns.equals(x_test.columns):\n",
    "        raise Exception('Datasets are incompatible!');\n",
    "    print('Datasets are compatible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40bc8e3f-0c25-4905-948e-53fb77de813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataset_file, input_cols, result_col):\n",
    "    x, y = prepare_dataset(train_dataset_file, input_cols, result_col)\n",
    "    \n",
    "    # Instantiate the model\n",
    "    model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "    # Train (=fit) the model\n",
    "    model.fit(x, y)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7949e3c9-e448-40b8-ac23-3042ade004fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dataset_file, input_cols, result_col):\n",
    "    x, y = prepare_dataset(test_dataset_file, input_cols, result_col)\n",
    "    \n",
    "    return model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2bc6f56-7a31-46ae-8458-2eebf64d8e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_for_input_combination(train_dataset_file, test_dataset_file, input_combination, result_col):\n",
    "    #print(input_cols_comb)\n",
    "    model = train_model(\n",
    "        train_dataset_file,\n",
    "        list(input_combination),\n",
    "        result_col\n",
    "    )\n",
    "    score = evaluate_model(\n",
    "        model,\n",
    "        test_dataset_file,\n",
    "        list(input_combination),\n",
    "        result_col\n",
    "    )\n",
    "    #print(score)\n",
    "    return score\n",
    "\n",
    "def run_input_optimizer(train_dataset_file, test_dataset_file, input_cols, result_col):\n",
    "    # Contains all combinations by input length (3D list)\n",
    "    input_combinations = []\n",
    "    for l in range(2, len(input_cols) + 1):\n",
    "        input_combinations.append(list(itertools.combinations(input_cols, l)))\n",
    "\n",
    "    scores = []\n",
    "    flat_input_combinations = []\n",
    "    \n",
    "    for input_combinations_of_len in input_combinations:\n",
    "        print('Testing combinations of length ' + str(len(input_combinations_of_len[0])))\n",
    "        \n",
    "        for input_combination in input_combinations_of_len:\n",
    "            score = _evaluate_for_input_combination(train_dataset_file, test_dataset_file, input_combination, result_col)\n",
    "            scores.append(score)\n",
    "            flat_input_combinations.append(input_combination)\n",
    "\n",
    "    # Pick and print results\n",
    "    max_score = max(scores)\n",
    "    max_score_idx = scores.index(max_score)\n",
    "    max_score_cols = flat_input_combinations[max_score_idx]\n",
    "\n",
    "    min_score = min(scores)\n",
    "    min_score_idx = scores.index(min_score)\n",
    "    min_score_cols = flat_input_combinations[min_score_idx]\n",
    "\n",
    "    print('Max score: ' + str(max_score))\n",
    "    print('Best columns combination: ' + str(max_score_cols))\n",
    "    print('Min score: ' + str(min_score))\n",
    "    print('Worse columns combination: ' + str(min_score_cols))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
