{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b2162fb-87b6-41e1-9317-9d687b9c160c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-17T11:15:46.878848Z",
     "start_time": "2023-04-17T11:15:45.194975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./venv/lib/python3.10/site-packages (1.24.2)\n",
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.10/site-packages (3.7.1)\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: openpyxl in ./venv/lib/python3.10/site-packages (3.1.2)\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.10/site-packages (1.2.2)\n",
      "Requirement already satisfied: seaborn in ./venv/lib/python3.10/site-packages (0.12.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.10/site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.10/site-packages (from matplotlib) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./venv/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.10/site-packages (from matplotlib) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./venv/lib/python3.10/site-packages (from matplotlib) (9.5.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./venv/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.10/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./venv/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: et-xmlfile in ./venv/lib/python3.10/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in ./venv/lib/python3.10/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in ./venv/lib/python3.10/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "import sys\n",
    "!{sys.executable} -m pip install numpy matplotlib pandas openpyxl scikit-learn seaborn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08a44b0a-736b-4f01-9b98-f0519aa27c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and global options\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import multiprocessing\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af73e3eb-3c1c-413a-8e83-03253b46b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset_file, input_cols, result_col=None):\n",
    "    \"\"\"Load a dataset and select the provided columns (w/ optional result column).\"\"\"\n",
    "    # Load data\n",
    "    df = pd.read_excel(dataset_file)\n",
    "    \n",
    "    # Filter bad data, replace categories with dummies\n",
    "    x_df = df[input_cols].apply(lambda x: x.str.strip())\n",
    "    x = pd.get_dummies(x_df, drop_first=True)\n",
    "    \n",
    "    if result_col:\n",
    "        y_df = df[result_col].str.strip()\n",
    "        y = pd.get_dummies(y_df, drop_first=True).iloc[:, 0]\n",
    "        \n",
    "        return x, y\n",
    "    else:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a791342c-2708-4e9a-b307-65cc5609a9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_input_data(dataset_file, input_cols):\n",
    "    \"\"\"Display data and dummies in a table.\"\"\"\n",
    "    x = prepare_dataset(dataset_file, input_cols)\n",
    "    display(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20ff6a4f-2ab8-4d7f-bddb-082a93769038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_input_data_indices(train_dataset_file, test_dataset_file, input_cols):\n",
    "    \"\"\"Check train and test dataset for compatibility, i.e. checks whether the provided input columns are present on both\"\"\"\n",
    "    x_train = prepare_dataset(train_dataset_file, input_cols)\n",
    "    x_test = prepare_dataset(test_dataset_file, input_cols)\n",
    "    \n",
    "    if not x_train.columns.equals(x_test.columns):\n",
    "        raise Exception('Datasets are incompatible!');\n",
    "    print('Datasets are compatible')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40bc8e3f-0c25-4905-948e-53fb77de813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataset_file, input_cols, result_col):\n",
    "    \"\"\"Create a logistic regression model on the provided dataset (including an expected result column) and fits/trains it on the result column.\"\"\"\n",
    "    x, y = prepare_dataset(train_dataset_file, input_cols, result_col)\n",
    "    \n",
    "    # Instantiate the model\n",
    "    model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "\n",
    "    # Train (=fit) the model\n",
    "    model.fit(x, y)\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7949e3c9-e448-40b8-ac23-3042ade004fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_dataset_file, input_cols, result_col):\n",
    "    \"\"\"Evaluate the provided model on the given test dataset, printing its score.\"\"\"\n",
    "    x, y = prepare_dataset(test_dataset_file, input_cols, result_col)\n",
    "    \n",
    "    return model.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2bc6f56-7a31-46ae-8458-2eebf64d8e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _evaluate_for_input_combination(train_dataset_file, test_dataset_file, input_combination, result_col):\n",
    "    #print(input_cols_comb)\n",
    "    model = train_model(\n",
    "        train_dataset_file,\n",
    "        list(input_combination),\n",
    "        result_col\n",
    "    )\n",
    "    score = evaluate_model(\n",
    "        model,\n",
    "        test_dataset_file,\n",
    "        list(input_combination),\n",
    "        result_col\n",
    "    )\n",
    "    #print(score)\n",
    "    return score\n",
    "\n",
    "def run_input_optimizer(train_dataset_file, test_dataset_file, input_cols, result_col):\n",
    "    \"\"\"Finds the best and worst combination of columns and their corresponding scores by brute force (by trying all the combinations).\"\"\"\n",
    "\n",
    "    # Contains all combinations by input length (3D list)\n",
    "    input_combinations = []\n",
    "    for l in range(2, len(input_cols) + 1):\n",
    "        input_combinations.append(list(itertools.combinations(input_cols, l)))\n",
    "\n",
    "    scores = []\n",
    "    flat_input_combinations = []\n",
    "    \n",
    "    for input_combinations_of_len in input_combinations:\n",
    "        print('Testing combinations of length ' + str(len(input_combinations_of_len[0])))\n",
    "        \n",
    "        for input_combination in input_combinations_of_len:\n",
    "            score = _evaluate_for_input_combination(train_dataset_file, test_dataset_file, input_combination, result_col)\n",
    "            scores.append(score)\n",
    "            flat_input_combinations.append(input_combination)\n",
    "\n",
    "    # Pick and print results\n",
    "    max_score = max(scores)\n",
    "    max_score_idx = scores.index(max_score)\n",
    "    max_score_cols = flat_input_combinations[max_score_idx]\n",
    "\n",
    "    min_score = min(scores)\n",
    "    min_score_idx = scores.index(min_score)\n",
    "    min_score_cols = flat_input_combinations[min_score_idx]\n",
    "\n",
    "    print('Max score: ' + str(max_score))\n",
    "    print('Best columns combination: ' + str(max_score_cols))\n",
    "    print('Min score: ' + str(min_score))\n",
    "    print('Worse columns combination: ' + str(min_score_cols))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
